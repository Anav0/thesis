The addition of partial state significantly changes how query results are
computed by the underlying dataflow system. This chapter demonstrates how
partial state is implemented in Noria such that it produces results similar to
those Noria would produce without partial state.

\section{Defining Correctness}

In order to discuss the degree to which partial achieves this goal, it is
necessary to first define what constitutes ``correct'' behavior, both in Noria
without partial, and with the introduction of partial.

\resume

\subsection{Correctness in Noria}

\subsection{Correctness with Partial State}

To give some intuition for why this problem is challenging, we first need to
understand what the goal of the system as a whole is. Ultimately, the partial
invariants all serve to maintain one principal property:

\begin{quote}
	If data stops flowing into the dataflow, the dataflow will eventually
	quiesce. When it does, for every key in every state, the value for that
	key is either missing, or it reflects the effects of each input to the
	system applied exactly once. A subsequent query for any missing key in
	any materialization populates the state for the missing key consistent
	with the property above for non-missing state.
\end{quote}

The intuition here is that Noria must \emph{at least} eventually do the right
thing. That is, it must make sure that all the data the application inserts into
the dataflow is considered, that none of it is double-counted, and that no other
spurious data is added. Unless, of course, the application has inserted dataflow
operators that double-count, in which case they should be exactly
double-counted.

We want Noria to provide stronger guarantees than eventual consistency whenever
possible and, in the common case, it does. Specifically, for most queries, Noria
ensures that a read from any given view sees complete query results as of some
recent time at each dataflow input. That is, for a given view, for each input
that feeds into that view, the view reflects a prefix of the data ingested by
that input. I call this \emph{prefix consistency}. Each view is also
continuously kept up to date; any new input is reflected in the view shortly
after being ingested, subject only to the propagation delay in the dataflow.

Noria does not necessarily provide prefix consistency when there are
\textbf{multiple} paths from a given dataflow input to a given view, such as
through a self-join. Depending on the precise semantics of the paths, this can
cause a view to briefly reflect \textbf{some} of the effects of newly inserted
data, but not all. For example, consider a self-join that computes a
parent-child relationship between records. If the application removes a record
$A$, that dataflow input must be processed along two edges. When it has been
processed by one edge, but no the other, the downstream view will briefly
continue to include $A$ as a child, even though it no longer appears as a
parent. This inconsistency is rectified once the dataflow input is also
processed on the second edge.

This problem is not directly related to partial state\,---\,Noria exhibits this
behavior when all state is fully materialized. However, partial state must work
in the context of such temporary inconsistencies. Furthermore, partial state
should not exaggerate these problems by introducing additional inconsistencies.

There are several situations that arise in a real dataflow implementation that
make even this seemingly simple property difficult to uphold. I sketch the
primary ones below, and give brief descriptions of my proposed solutions. In my
thesis, I will go into these in greater detail. I will also provide a more
comprehensive analysis of the possible inconsistencies that can arise if these
situations are not handled correctly by the partial state logic.

At its core, partial state introduces two new conditions into the dataflow that
were not previously present. First, multiple updates may now be collapsed and
re-processed through the dataflow as a single, consolidated update in response
to an upquery. These consolidated updates represent \textit{snapshots} of
upstream state, and the system must ensure that these snapshots do not introduce
duplicate or spurious query results, or fail to include relevant data.

Second, with partial state in place, \emph{any} operator processing may
encounter missing state. When that happens, the system

How do we know that Noria is eventually consistent?

First, how do we know that Noria without partial state is eventually
consistent. And second, how do we know that Noria remains eventually
consistent with partial state.

We don't have a formal proof for either. Ignoring implementation bugs, the
informal argument goes something like:

For partial state, we need to show that each of the things that have been
changed preserve eventual consistency. First, sending a snapshot of past state
(upquery response) is equivalent to sending the individual updates that made
up that snapshot since the operators are distributive and commutative. Second,
upquery results can race with related updates, which is handled by the various
challenges I listed in the proposal:

 - sending them inline in the dataflow (for single-branch)
 - union buffering (for unioned branched dataflow)
 - special join upquery handling (for joined branched dataflow)

And third, partial state means that lookups can miss internally in the
dataflow, which is handled by join eviction when related state may still be
present downstream, and by discarding the update when it is not.

\section{Linear Dataflow}

First, consider a single strand of dataflow, where each operator has at most one
input and at most one output. For partial state to be correct, it must be the
case that computing missing results with an upquery that combines all past
deltas into a single update produces the same results as processing the deltas
one-at-a-time.

\begin{inprogress}
  What about discarded updates in the paragraph below?
\end{inprogress}

The deltas that flow through the dataflow system represent changes to the
logical output state of the operator that produced the delta. If a base table
produces a negative delta for a row $r$, it means that row $r$ is no longer part
of that base table's current state. An upquery fetches current state, which is
the sum of all past deltas emitted by the queried operator, and then feeds it
through the same chain of dataflow operators that individual deltas go through.
For upquery processing to be equivalent to one-at-a-time delta processing, it
must be the case that with operators $f_1$ through $f_N$, and past deltas $d_1$
through $d_M$:

\begin{eqnarray*}
  \sum^M_{i=1}\left(f_N \circ \dots \circ f_1\right)\left(d_i\right) = \
  \left(f_N \circ \dots \circ f_1\right)\left(\sum^M_{i=1}d_i\right)
\end{eqnarray*}

With a single operator, this trivially holds since all Noria operators are
distributive over delta addition:

\begin{eqnarray*}
  \sum^M_{i=1}f\left(d_i\right) = \
  f\left(\sum^M_{i=1}d_i\right)
\end{eqnarray*}

Using this property, and the fact that all operators produce and consume deltas,
it is possible to ``shift'' the delta sum across operator compositions:

\begin{eqnarray*}
  \sum^M_{i=1}\left(f_{n+1} \circ f_n\right)\left(d_i\right) &=& \sum^M_{i=1}f_{n+1}\left(f_n\left(d_i\right)\right) \\
  &=& f_{n+1}\left(\sum^M_{i=1}f_n\left(d_i\right)\right) \\
  &=& f_{n+1}\left(f_n\left(\sum^M_{i=1}d_i\right)\right) \\
  &=& \left(f_{n+1} \circ f_n\right)\left(\sum^M_{i=1}d_i\right)
\end{eqnarray*}

Therefore, the same ultimate state results whether the system executes each
dataflow operator in sequence on individual deltas, or whether it first sums
all the deltas into a single update, and then executes the operators in sequence
over that. Or, stated differently, if normal dataflow processing produces the
correct result, so too must processing a combined upquery response.

\section{Diverging Dataflow}

Dataflow graphs in real applications are rarely linear. They contain branches
where the dataflow diverges, such as if two views both contain data from the
same table. When the dataflow diverges, the biggest change from partial state is
that upstream operators may receive multiple upqueries for the same data. This
happens if multiple downstream views encounter missing entries that rely on the
same upstream data.

The primary concern in this case is that the multiple upquery responses not
result in data duplication\,---\,if a stateful operator processes two upquery
responses that both reflect some base table row, the effects of that row are now
duplicated in the operator's state. Since upquery results only ever flow along
the same edges that the upquery followed on its way up the dataflow
(\S\ref{s:upqueries}), duplicates are only a concern for state that is on the
upquery path\,---\,state on other branches will never see the upquery response
in the first place.

\S\ref{s:upquery:selection} noted that upquery paths are trimmed such that they
only reach back to the \emph{nearest} materialized state to the target. Beyond
improving efficiency, this is also important for correctness. It ensures that
there are no stateful operators on the upquery path between the source and the
destination. If there were, that operator's state would be used as the upquery
source instead. Since it is safe to process the same record through a stateless
operator multiple times, this ensures that the processing of the upquery
response on the path to the target state never duplicates effects.

\section{Merging Dataflow}

In practice, most applications include at least one join or union in their
queries. When they do, strands of dataflow combine to produce joint output that
depends on multiple inputs. And crucially, such dataflow constructions introduce
the possibility of data races. Now, updates may arrive to an operator from two
inputs in parallel, and the operator may process either update before the other.
Furthermore, upqueries must now retrieve data from \emph{all} ancestors, and
ensure that they are combined in such a way that no duplicate or spurious data
is introduced, and no data is missed.

How upqueries work across multi-ancestor operators depends on the semantics of
that operator. The two primary relational multi-ancestor operators, unions and
joins, are discussed below.

\subsection{Unions}

Unions merely combine the input streams of their ancestors, and includes little
processing beyond column selection. An operator that wishes to upquery past this
operator must therefore \emph{split} its upquery; it must query each ancestor of
the operator, and take the union of the responses to populate all the missing
state.

With concurrent processing, the multiple resulting responses may be arbitrarily
delayed between the different upquery paths, which can cause issues. Consider
a union, U, across two inputs, A and B, with a single materialized and partial
downstream operator C. C discovers that it needs the state for $k = 1$, and
sends an upquery for $k = 1$ to both A and B. A responds first, and C receives
that response.

First, C needs to remember that the missing state is still missing, so that it
does not expose incomplete state downstream. For example, if it received an
upquery for $k = 1$, it could not reply with \textbf{just} A's state.

Now imagine that both A and B send one normal dataflow message each, and that
they both include data for $k = 1$. When these messages reach C, C faces a
dilemma. It cannot drop the messages, since the message from A includes data
that was not included in A's upquery response. If it dropped them, that data
would disappear forever, and results downstream would be permanently stale. But
it also cannot apply the messages, since B's message includes data that will be
included in B's eventual upquery response. If it did, that data would be
duplicated.

\begin{listing}[h]
  \begin{minted}{python}
if is_upquery_response(d):
  buffered <- buffer[upquery_path_group(d)][key(d)]
  if len(buffered) == ninputs - 1:
    # this is the last upquery response piece.
    # emit a single, combined response
    emit(sum(buffered) + d)
    delete buffered
  else:
    # need responses from other parallel upqueries.
    buffered[from(d)] = d
    discard(d)
else:
  # this is a normal dataflow delta.
  # see if any changes in the delta
  # affect buffered upquery responses.
  for group_id, key_buffers in buffer:
    for change in d:
      change_key <- change[key_column(group_id)]
      # note the dependence on from(d) below.
      # changes from parents that have not produced
      # an upquery response yet are ignored; they
      # are represented in the eventual response.
      buffered <- key_buffers[change_key][from(d)]
      if buffered:
        buffered += change
  # always emit the delta, as other downstream
  # state may depend on it. any operator that is
  # waiting for missing state will discard.
  emit(d)
  \end{minted}
  \caption{Pseudocode for union buffering algorithm upon receiving a delta
  \texttt{d}. \texttt{buffer} starts out as an empty dictionary.
  \texttt{upquery\_path\_group} is discussed in the text.}
  \label{l:union-buffer}
\end{listing}

To mitigate this problem, unions must \textit{buffer} upquery results until
\emph{all} their inputs have responded. In the meantime, they must \emph{also}
buffer updates for the buffered upquery keys to ensure that a single, complete,
upquery response is ultimately emitted. Listing~\ref{l:union-buffer} shows
pseudocode for the buffering algorithm.

For unions to buffer correctly, they must know which upquery responses belong to
the ``same'' upquery. If there is only one upquery path through the union to
each ancestor, this is straightforward, as all upquery responses for a key $k$
are responses to the same upquery, and should be combined. However, in more
complex dataflow layouts, this is not always the case.

\begin{figure}[t]
  \centering
  \includegraphics{diagrams/Chained Unions.pdf}
  \caption{Chained unions. Only nodes $a$, $b$, and $v$ hold state. Highlighted
  in orange are two upquery paths that $\cup_1$ must combine upquery responses
  for.}
  \label{f:chained-union}
\end{figure}

Figure~\ref{f:chained-union} shows a dataflow segment where the precise grouping
mechanism is important (\texttt{upquery\_path\_group} in the code listing).
There are three unions in a chain, which makes eight distinct upquery paths. If
$v$ encounters missing state, it must therefore issue eight upqueries, one for
each path. $a$ and $b$ both appear as the root of four paths, and will be
upqueried that many times. The issue arises at the unions, which need to do
the aforementioned union buffering.

Ultimately, a single upquery response must reach $v$. This means that $\cup_3$
must receive two upquery responses, one from $e$ and one from $f$, which it must
then combine. So $\cup_2$ must \emph{produce} two upquery responses, one
destined for $e$ and one for $f$. This in turn means that $\cup_2$ must receive
two upquery responses from $c$, and two from $d$. Which again means that
$\cup_1$ must produce four responses, two for $c$ and two for $d$, out of the
eight responses it receives (four from $a$ and four from $b$).

These are all the upqueries that pass through $\cup_1$:
        
\begin{multicols}{4}
\begin{description}
  \item [1.] $a\,\to\,c\,\to\,e$
  \item [2.] $a\,\to\,c\,\to\,f$
  \item [3.] $a\,\to\,d\,\to\,e$
  \item [4.] $a\,\to\,d\,\to\,f$
  \item [5.] $b\,\to\,c\,\to\,e$
  \item [6.] $b\,\to\,c\,\to\,f$
  \item [7.] $b\,\to\,d\,\to\,e$
  \item [8.] $b\,\to\,d\,\to\,f$
\end{description}
\end{multicols}

$\cup_1$ must combine these in pairs such that every downstream union receives
the responses that they expect from each of their inputs. The grouping that
achieves this is:

\begin{multicols}{2}
\begin{description}
  \item [1/5.] $a/b\,\to\,c\,\to\,e$
  \item [2/6.] $a/b\,\to\,c\,\to\,f$
  \item [3/7.] $a/b\,\to\,d\,\to\,e$
  \item [4/8.] $a/b\,\to\,d\,\to\,f$
\end{description}
\end{multicols}

The key observation is that the distinction between $a$ and $b$ does not matter
any longer downstream of $\cup_1$; a delta that arrived from $a$ is
indistinguishable from one that arrived from $b$. Similarly, the distinction
between $c$ and $d$ no longer matters past $\cup_2$, and the same for $e$ and
$f$ past $\cup_3$. \texttt{upquery\_path\_group} is thus defined as a unique
identifier for $v$'s upquery plan plus the sequence of nodes between the union
and the target of the upquery response.

\subsection{Joins}

For unions, as we saw above, the upquery must go to all the ancestors. For joins
on the other hand, the upquery must only go to \textbf{one} ancestor. This is
because when a join processes a message from one ancestor, it already queries
the ``other'' ancestor and thus pulls in any relevant state. If both sides of
the join were queried, the processing of the upquery responses at the join would
produce duplicates of every record.

For a symmetric join, either ancestor can be the target of the upquery, whereas
for an asymmetric join (like a left join), the upquery \emph{must} go to the
``full'' side\,---\,the side from which all rows are yielded. Otherwise, the
upquery may produce only a subset of the results for the join.

\subsubsection{Dependent Upqueries}

When a upquery response passes through a join operator, the join performs
lookups into the state of the other side of the join. With partial state, those
lookups may themselves encounter missing entries. When this happens, a problem
arises: the system \emph{must} produce an downstream upquery response because
the application is waiting for it, but it cannot produce that response since
required state is missing.

For the purposes of exposition, and without loss of generality, the text below
refers to the join ancestor that was upqueried as the left side, and the
ancestor that a lookup missed in as the right side.

The join must issue an upquery to the right hand side for the state that is
missing to complete the processing of the original upquery response. However,
this \textit{dependent upquery} may take some time to complete, and the system
must decide what to do in the meantime. Recall that the join is still in the
middle of processing an upquery response.

An obvious, but flawed strategy is to have the join block until the response
arrives. This would not only stall processing of deltas from the left parent,
but also leads to a deadlock. In order to observe the eventual upquery response,
the join's domain must continue to process incoming messages to the right parent
(\S\ref{s:join-state-dupe}). But in doing so, it may encounter a different
upquery response from the right parent. That upquery response may require a
lookup into the left parent's state, which may itself encounter missing entries.
The join is then forced to block on both inputs perpetually.

Instead, the join \emph{discards} the current upquery response, and notes down
the upquery parameters that triggered it, and the missing state it is waiting to
be filled. It then continues processing as normal. When all the missing entries
are eventually filled in, the system \emph{re-issues} the original upquery to
the join's left parent using the parameters it saved. This time, when the
upquery response arrives, the lookups into the right-hand parent's state, all
required entries should be present, and the downstream upquery response is
produced. As far as the downstream dataflow is concerned, nothing abnormal has
happened\,---\,the upquery response just took longer to arrive.

\subsubsection{Incongruent Joins}

The system must guarantee that all data relevant to a given state entry
eventually reaches the operator that holds that entry. A corollary of this is
that the system cannot discard messages that may affect non-missing, downstream
state. Normally, this is the case, since upqueries traverse the dataflow from
the leaves and up, and fill entries from the top down as the responses flow down
the dataflow. If some key $k$ is present in a materialization $m$, it must also
be present at every materialization above $m$ from the upquery chain that
ultimately produced the entry for $k$ in $m$.

Unfortunately, certain query graphs produce dataflow where more than one key is
used in the dataflow to compute an entry. Consider a dataflow that joins two
inputs, \texttt{story} and \texttt{user}, on the story's author field. A
downstream operator issues an upquery for story number 7. The upquery is issued
to \texttt{story}, which produces a message that contains story number 7 with,
say, author ``Elena''. That message arrives at the join, which issues a
dependent upquery to \texttt{user} for ``Elena''. When that dependent upquery
resolves, the join produces the final upquery response, and the state for story
number 7 is populated in the downstream materialization.

Next, an editor changes the author for story number 7 to ``Talia''. This
takes the form of a delta with a negative multiplicity record for \texttt{[7,
"Elena"]} and a positive one for \texttt{[7, "Talia"]}. When this delta arrives
at the join, it may now miss when performing the lookup for ``Talia''. According
to the partial model so far, the join should now drop \texttt{[7, "Talia"]}, and
only allow the negative for ``Elena'' to propagate to the downstream
materialization. When that happens,  the state for article number 7 becomes
empty (though not missing), and any subsequent read for article number 7
receives an empty response, which violates correctness.

What happened here was that the entry for key $k$ in the leaf-most
materialization depends not only on state entries indexed by the same $k$
upstream, but also on state entries indexed by other keys upstream. While $k$
must be present upstream, no such guarantee exists for other keys.

This is a result of \textit{incongruent joins}; joins whose join column is not
the same as the downstream key column. Incongruence is determined with respect
to each upquery path that flow through a join. In the case above, the author
join is incongruent with an upquery on the story number column, since the join
column is the author column. However, the join is congruent with upqueries from
a hypothetical downstream view that is keyed by author instead. A join that is
incongruent with any upquery path that flows through it is considered an
incongruent join.

The system can easily recognize incongruent joins through key provenance
analysis\,---\,if an upquery flows through a join, and the upquery column is not
the same as the join column, the join is incongruent. If the system then
observes that an incongruent join encounters missing state while processing a
delta at runtime, it must take action to ensure that downstream state remains
correct. Since the domain that processes the join cannot produce a valid delta,
and does not know what state is present and missing in the downstream dataflow,
its only option is to issue an eviction for any downstream state that \emph{may}
be rendered stale. Concretely, if an incongruent join processes a record $r$ and
encounters a missing state entry, it should issue an eviction downstream on all
incongruent upquery paths using the appropriate values from $r$. For example, if
the join column is $c_j$, and upquery path $u_i$ through the join is keyed by
column $c_i$, then the join should issue downstream evictions of $r[c_i]$ for
each $u_i$ where $c_i \neq c_j$.

\section{Sharding}

\resume

Noria supports sharding cliques of operators to increase the throughput
of particular sections of the dataflow. Shards of an operator execute in
parallel, without synchronization. Edges that cross from an unsharded
operator to a sharded one split its outgoing updates using hash
partitioning. Edges that cross back have an implicit union injected to
merge the sharded results. Edges that cross from one sharding to a
different sharding are merged and then split again. Upqueries must also
work when Noria decides to shard operators in this way.

Upqueries across a sharding boundary are a complicated affair. The
operator that issues the upquery must determine which shard or shards to
send the upquery to. If it queries multiple shards, the responses from
those shards are subject to the same multi-ancestor issue as unions.
When a response to the upquery comes back, it must be specifically
routed to only the requesting shard, so that it does not accidentally
populate the state of other shards. This logic must work even if
multiple shards issue an upquery for the same key concurrently. Or,
worse yet, if a single upquery must traverse \textbf{multiple} sharding
boundaries.

\paragraph{Noria solution}
Key provenance informs operators whether an upquery for a given column should be
sent to all shards, or just one shard, of the upquery source. This information,
as well as the shard identifier of the requesting operator, is included in the
upquery itself, and in the eventual response. Sharding unions buffer upquery
responses that originated from more than one shard (like regular unions). Shard
``splitters'' ensure that responses only arrive at the requesting shard using
the requestor information in the response.

\begin{inprogress}
  Diamonds?
\end{inprogress}
