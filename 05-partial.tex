The addition of partial state significantly changes how query results are
computed by the underlying dataflow system. This chapter demonstrates how
partial state is implemented in Noria such that it produces results similar to
those Noria would produce without partial state.

\section{Defining Correctness}

In order to discuss the degree to which partial achieves this goal, it is
necessary to first define what constitutes ``correct'' behavior, both in Noria
without partial, and with the introduction of partial.

\resume

\subsection{Correctness in Noria}

\subsection{Correctness with Partial State}

To give some intuition for why this problem is challenging, we first need to
understand what the goal of the system as a whole is. Ultimately, the partial
invariants all serve to maintain one principal property:

\begin{quote}
	If data stops flowing into the dataflow, the dataflow will eventually
	quiesce. When it does, for every key in every state, the value for that
	key is either missing, or it reflects the effects of each input to the
	system applied exactly once. A subsequent query for any missing key in
	any materialization populates the state for the missing key consistent
	with the property above for non-missing state.
\end{quote}

The intuition here is that Noria must \emph{at least} eventually do the right
thing. That is, it must make sure that all the data the application inserts into
the dataflow is considered, that none of it is double-counted, and that no other
spurious data is added. Unless, of course, the application has inserted dataflow
operators that double-count, in which case they should be exactly
double-counted.

We want Noria to provide stronger guarantees than eventual consistency whenever
possible and, in the common case, it does. Specifically, for most queries, Noria
ensures that a read from any given view sees complete query results as of some
recent time at each dataflow input. That is, for a given view, for each input
that feeds into that view, the view reflects a prefix of the data ingested by
that input. I call this \emph{prefix consistency}. Each view is also
continuously kept up to date; any new input is reflected in the view shortly
after being ingested, subject only to the propagation delay in the dataflow.

Noria does not necessarily provide prefix consistency when there are
\textbf{multiple} paths from a given dataflow input to a given view, such as
through a self-join. Depending on the precise semantics of the paths, this can
cause a view to briefly reflect \textbf{some} of the effects of newly inserted
data, but not all. For example, consider a self-join that computes a
parent-child relationship between records. If the application removes a record
$A$, that dataflow input must be processed along two edges. When it has been
processed by one edge, but no the other, the downstream view will briefly
continue to include $A$ as a child, even though it no longer appears as a
parent. This inconsistency is rectified once the dataflow input is also
processed on the second edge.

This problem is not directly related to partial state\,---\,Noria exhibits this
behavior when all state is fully materialized. However, partial state must work
in the context of such temporary inconsistencies. Furthermore, partial state
should not exaggerate these problems by introducing additional inconsistencies.

There are several situations that arise in a real dataflow implementation that
make even this seemingly simple property difficult to uphold. I sketch the
primary ones below, and give brief descriptions of my proposed solutions. In my
thesis, I will go into these in greater detail. I will also provide a more
comprehensive analysis of the possible inconsistencies that can arise if these
situations are not handled correctly by the partial state logic.

At its core, partial state introduces two new conditions into the dataflow that
were not previously present. First, multiple updates may now be collapsed and
re-processed through the dataflow as a single, consolidated update in response
to an upquery. These consolidated updates represent \textit{snapshots} of
upstream state, and the system must ensure that these snapshots do not introduce
duplicate or spurious query results, or fail to include relevant data.

Second, with partial state in place, \emph{any} operator processing may
encounter missing state. When that happens, the system

\section{Linear Dataflow}

First, consider a single strand of dataflow, where each operator has at most one
input and at most one output. For partial state to be correct, it must be the
case that computing missing results with an upquery that combines all past
deltas into a single update produces the same results as processing the deltas
one-at-a-time.

\begin{inprogress}
  What about discarded updates in the paragraph below?
\end{inprogress}

The deltas that flow through the dataflow system represent changes to the
logical output state of the operator that produced the delta. If a base table
produces a negative delta for a row $r$, it means that row $r$ is no longer part
of that base table's current state. An upquery fetches current state, which is
the sum of all past deltas emitted by the queried operator, and then feeds it
through the same chain of dataflow operators that individual deltas go through.
For upquery processing to be equivalent to one-at-a-time delta processing, it
must be the case that with operators $f_1$ through $f_N$, and past deltas $d_1$
through $d_M$:

\begin{eqnarray*}
  \sum^M_{i=1}\left(f_N \circ \dots \circ f_1\right)\left(d_i\right) = \
  \left(f_N \circ \dots \circ f_1\right)\left(\sum^M_{i=1}d_i\right)
\end{eqnarray*}

With a single operator, this trivially holds since all Noria operators are
distributive over delta addition:

\begin{eqnarray*}
  \sum^M_{i=1}f\left(d_i\right) = \
  f\left(\sum^M_{i=1}d_i\right)
\end{eqnarray*}

Using this property, it is possible to ``shift'' the delta sum across operator
compositions:

\begin{eqnarray*}
  \sum^M_{i=1}\left(f_{n+1} \circ f_n\right)\left(d_i\right) &=& \sum^M_{i=1}f_{n+1}\left(f_n\left(d_i\right)\right) \\
  &=& f_{n+1}\left(\sum^M_{i=1}f_n\left(d_i\right)\right) \\
  &=& f_{n+1}\left(f_n\left(\sum^M_{i=1}d_i\right)\right) \\
  &=& \left(f_{n+1} \circ f_n\right)\left(\sum^M_{i=1}d_i\right)
\end{eqnarray*}

Therefore, the same ultimate state results whether the system executes each
dataflow operator in sequence on individual deltas, or whether it first sums
all the deltas into a single update, and then executes the operators in sequence
over that. Or, stated differently, if normal dataflow processing produces the
correct result, so too must processing a combined upquery response.

\section{Diverging Dataflow}

Dataflow graphs for real applications are rarely linear. They contain branches
where the dataflow diverges, such as if two views both contain data from the
same table.

\resume

\section{Merging Dataflow}

In practice, most applications include at least one join or union in their
queries. When they do, strands of dataflow combine to produce joint output that
depends on both inputs. And crucially, such dataflow constructions introduce the
possibility of data races. Now, updates may be arriving to an operator from two
inputs in parallel, and the operator may process either update before the other.
Furthermore, upqueries must now retrieve data from \emph{all} ancestors, and
ensure that they are combined in such a way that no duplicate or spurious data
is introduced, and no data is missed.

\resume

Operators that have multiple ancestors pose a problem to the partial
model. Consider an identity operator that merely combines the input
streams of its ancestors (i.e., a union). An upquery that crosses this
operator must \emph{split} its upquery; it must query each ancestor of the
operator, and take the union of the responses to populate missing state.
But when we allow concurrent processing, these responses may be
arbitrarily delayed between the different upquery paths.

Let's examine what happens with a union, U, across two inputs, A and B,
and a single materialized and partial downstream operator C. C discovers
that it needs the state for $k = 1$, and sends an upquery for $k = 1$ to
both A and B. A responds first, and C receives that response. It needs
to remember that the missing state is still missing, so that it does not
expose incomplete state downstream (e.g., if it received an upquery for
$k = 1$, it could not reply with \textbf{just} A's state). Now imagine that
both A and B send one normal dataflow message each, and that they both
include data for $k = 1$. When these messages reach C, C faces a
dilemma. It cannot drop the messages, since the message from A includes
data that was not included in A's upquery response. If it dropped them,
that data would disappear forever, which violates our primary system
property. But it also cannot apply the messages, since B's message
includes data that will be included in B's eventual upquery response. If
it did, that data would be duplicated.

How upqueries work across multi-ancestor operators depends on the
semantics of that operator. For unions, as we saw above, the upquery
must go to all the ancestors. For joins on the other hand, the upquery
must only go to \textbf{one} ancestor. This is because when a join processes
a message from one ancestor, it already queries the ``other'' ancestor and
thus pulls in any relevant state. In the example above, if U were a
join, then if C sent an upquery to both A and B, the two upquery
responses it received would contain duplicate data. For a symmetric
join, the responses would in fact be identical, whereas for an
asymmetric join (like a left join), they would differ. This suggests
that we must determine the algorithm for upqueries across each type of
multi-ancestor operator separately. Unions, joins, and left joins for
example all have different upquery restrictions.

\subsection{Unions}

Unions must buffer upquery results until all their inputs have responded. In the
meantime, they must buffer updates for the buffer upquery keys to ensure that a
single, complete, upquery response is emitted.

\subsection{Congruent Joins}

Joins already contain implied upqueries, so only one side must be upqueried,
with the upqueries to the other side left to the join itself. Left joins work
the same way, but with the additional restriction that the initial upquery
\emph{must} go the left input.

Sometimes, an operator must issue an upquery upstream in order to
satisfy an upquery from downstream. I refer to a recursive upquery like
this as a \emph{dependent} upquery. Dependent upqueries are not, in and of
themselves, complicated. They function exactly like a regular upquery.
However, it turns out they pose a challenging system design problem.

Upquery responses must, in some sense, be atomic. They must occur at
some single logical point in time with respect to an operator's input
and output streams. Consider what happens if an operator is part-way
through processing an upquery response, and discovers that it must
perform a dependent upquery in order to complete that processing. It may
be a while before the dependent upquery resolves, and in the meantime
the operator needs to decide what to do.

If it blocks waiting for the response to come back, it holds up all
processing of other upqueries and writes. That would not be great. On
the other hand, if it continues processing other inputs, it risks
dropping or duplicating inputs; any part of the upquery response it
produced \textbf{before} it found the need for the dependent query still
reflects the state at that point in time. Since it may have processed
writes since then that affect that computed state, the upquery response
would no longer reflect a current, atomic snapshot.

\paragraph{Noria solution}
Operators issue dependent upqueries only if the need arises while processing an
upquery response. Otherwise, that part of the current update is discarded. If a
dependent upquery must be issued to complete processing some past upquery
response, the response is dropped, the dependent upquery is issued, and the
operator re-tries the original upquery when the dependent upquery resolves.

\begin{inprogress}
  Should also mention self-lookups on different columns (are there any?).
\end{inprogress}

\subsection{Incongruent Joins}

We have to guarantee that all data relevant to a given state entry
eventually reaches that state. A corollary of this is that we cannot
discard messages that may affect non-missing, downstream state.
Normally, this is the case, since upqueries traverse the dataflow from
the leaves and ``up''\,---\,if some key $k$ is present at an edge down the
graph, it is also present at every materialization above that edge, and
therefore messages with key $k$ will not be discarded early.

Unfortunately, this only holds for upqueries where all dependent
upqueries share the same key as the leaf-most upquery. Consider a
dataflow that joins two inputs, \texttt{Article} and \texttt{User}, on the article's
author field. A downstream operator then issues an upquery for article
number 7. The upquery is issued to \texttt{Article}, which produces a message
that contains article number 7 with, say, author ``Elena''. That message
arrives at the join, which issues a dependent upquery to \texttt{User} for
``Elena''. When that dependent upquery resolves, the join produces the
final upquery response, and the state for article number 7 is populated
in the downstream materialization.

Next, an editor changes the author for article number 7 to ``Talia''. This
takes the form of a message with a negative for \texttt{[7, "Elena"]} and a
positive for \texttt{[7, "Talia"]}. When this message arrives at the join, it
may miss when performing the lookup for ``Talia''. The join therefore
drops \texttt{[7, "Talia"]}, and only the negative for ``Elena'' propagates to
the downstream materialization. It then marks the state for article
number 7 as empty (though not missing). Any subsequent read for article
number 7 receives an empty response, which violates our primary system
property.

\paragraph{Noria solution}
Key provenance analysis detects when the dataflow downstream of an operator has
this property. With that information, an operator knows when it is about to drop
an update that \emph{may} nonetheless exist in downstream state. It issues an
eviction for that state, ensuring that if the updated state is subsequently
needed, it will be queried for.

\section{Diamonds}

\section{Sharding}

Noria supports sharding cliques of operators to increase the throughput
of particular sections of the dataflow. Shards of an operator execute in
parallel, without synchronization. Edges that cross from an unsharded
operator to a sharded one split its outgoing updates using hash
partitioning. Edges that cross back have an implicit union injected to
merge the sharded results. Edges that cross from one sharding to a
different sharding are merged and then split again. Upqueries must also
work when Noria decides to shard operators in this way.

Upqueries across a sharding boundary are a complicated affair. The
operator that issues the upquery must determine which shard or shards to
send the upquery to. If it queries multiple shards, the responses from
those shards are subject to the same multi-ancestor issue as unions.
When a response to the upquery comes back, it must be specifically
routed to only the requesting shard, so that it does not accidentally
populate the state of other shards. This logic must work even if
multiple shards issue an upquery for the same key concurrently. Or,
worse yet, if a single upquery must traverse \textbf{multiple} sharding
boundaries.

\paragraph{Noria solution}
Key provenance informs operators whether an upquery for a given column should be
sent to all shards, or just one shard, of the upquery source. This information,
as well as the shard identifier of the requesting operator, is included in the
upquery itself, and in the eventual response. Sharding unions buffer upquery
responses that originated from more than one shard (like regular unions). Shard
``splitters'' ensure that responses only arrive at the requesting shard using
the requestor information in the response.

\section{Miscellaneous Lifted Text}

\begin{inprogress}
  Nothing should remain in this section.
\end{inprogress}

\subsection{Consistency}

How do we know that Noria is eventually consistent?

First, how do we know that Noria without partial state is eventually
consistent. And second, how do we know that Noria remains eventually
consistent with partial state.

We don't have a formal proof for either. Ignoring implementation bugs, the
informal argument goes something like:

For partial state, we need to show that each of the things that have been
changed preserve eventual consistency. First, sending a snapshot of past state
(upquery response) is equivalent to sending the individual updates that made
up that snapshot since the operators are distributive and commutative. Second,
upquery results can race with related updates, which is handled by the various
challenges I listed in the proposal:

 - sending them inline in the dataflow (for single-branch)
 - union buffering (for unioned branched dataflow)
 - special join upquery handling (for joined branched dataflow)

And third, partial state means that lookups can miss internally in the
dataflow, which is handled by join eviction when related state may still be
present downstream, and by discarding the update when it is not.
