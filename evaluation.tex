The work in this thesis is built on the belief that materialization is useful,
and that partial materialization is necessary to make it practical for an
important class of applications. Without materialization, queries must either be
manually cached, which is labor-intensive and error-prone, or be computed on
demand, which is slow. And with full state materialization, all queries are
fast, but the memory cost is prohibitive for any but the smallest applications.
Whereas partial state allows you to trade off application tail latency for
reduced memory use.

In this section, I provide experimental and qualitative evidence that this
belief is warranted through analysis of the following questions:

\begin{enumerate}
 \item What impact does partial state have on memory use? \S\ref{s:eval:mem}
 \item How dependent is partial state on application access patterns? \S\ref{s:eval:patterns}
 \item What is the cost of using partial state? \S\ref{s:eval:cost}
 \item How does partial state compare to existing solutions? \S\ref{s:eval:existing}
\end{enumerate}

The high-level take-away from this section is that partial state allows
read-heavy applications with skewed access patterns to operate using
significantly less memory, with marginal impact on system throughput and
latency.

\section{What impact does partial state have on memory use?}
\label{s:eval:mem}

The primary motivation behind reducing application memory use is to reduce cost.
Higher memory use requires more memory, and more memory costs more, both in
purchasing and in ongoing power consumption. An application that uses less
memory can scale further on the same hardware, or, conversely, can run on
smaller hardware than would otherwise be needed.

The key question for partially stateful dataflow then is whether it truly and
meaningfully reduces application memory use. Or, more accurately, whether
applications can run efficiently when only some of its query results are cached.
Intuitively, one might expect this to be true for many user-driven applications:
some queries may only be executed for rarely used features, and unpopular posts
may be accessed only very infrequently, or perhaps not at all, after they were
initially posted.

To validate this, I used production statistics from the open-source Lobsters
news aggregator~\cite{lobsters,lobsters-data} to build a benchmarking harness
that approximates the page access patterns the real Lobsters website sees. The
load generator is ``partially open-loop'' to ensure that clients maintain the
measurement frequency even during periods of high latency, and also measure
queueing time~\cite{frank-open-loop,open-loop-cautionary-tale}. Since Lobsters
is a small site, relatively speaking, the harness also lets me to proportionally
scale up the access frequency to evaluate a larger deployment with the same
data and query access patterns.

I then wrote a Noria implementation for each Lobsters page endpoint that
queries the same data, and performs the same writes as the real Ruby-on-Rails
application.%
\footnote{I opted to do this rather than run the Ruby-on-Rails code directly to
avoid measuring Ruby and Rails bottlenecks.}
Together, these allow me to measure the throughput, latency, and memory overhead
that Noria would provide if used as the backend for Lobsters as it scales up.

Figure~\ref{f:lobsters-memory} shows the memory use with and without partial
materialization at a scale-up factor of 4000%
\footnote{When Noria runs without partial, this is the highest factor that still
fits in the 128GB of memory of the host machine.}
times normal Lobsters load. The figure also shows the lowest memory limit Noria
can sustain without (COMPROMISING LATENCY?) when eviction is enabled.

\begin{figure}[t]
  \centering
  \includegraphics{graphs/lobsters-memory.pdf}
  \caption{Lobsters memory use full/partial (many things not accessed) and partial/evict (many things infrequently accessed).}
  \label{f:lobsters-memory}
\end{figure}

Note difference between value here and VMRSS!

Note that evict is necessary because, over time, more and more of the
tail will be sampled. Without eviction, eventually the entire tail would
be kept in memory (so == full).

Partial state also enables efficient migrations in many cases. Any view
that can be made partial (ref section + later eval) is immediately
available, and does not compute until requested.

Fig.: vote-migration skewed partial vs full

\section{How dependent is partial state on application access patterns?}
\label{s:eval:patterns}

Materialization is generally useful when reads are more common than
writes, since it shifts the computation from reads to writes.
But, without partial state, materialization is an ``off/on'' option —
either you materialize all the results for a query, or none [TODO: not
quite true — more subtlety here — depends what you mean by ``query''
(e.g., parameterized or not)].

Partial state (and caching in general) enables \textbf{selective}
materialization. This makes sense if most application accesses are for
a particular subset of the dataset. That is, accesses are \textit{skewed}
towards particular data. In applications with skewed access patterns
(common — ref log-normal + Lobsters above), you can choose to only
materialize commonly-accessed results, rather than all. This uses
potentially far less memory (as indicated above), while still giving you
a speedup for \textbf{most} accesses. The more memory you provide the partial
system with, the more of your tail will be pre-computed, and the more of
your requests will be fast.

Fig.: mem limit vs latency [mean/50/95/99] in Lobsters.

Deciding what memory limit to set is challenging, in part because it
may change over time as the access patterns change, and in part because
it depends on load. The higher the load, the more requests will be in
the tail (and miss). Of course, more requests will be in the head too.

Fig.: throughput vs 95\%-ile latency [memlimits] in vote.

For example, for Zipf distribution, we can compute \%s:

Tab.: | load | skew | keys hit in 30s | keys hit by 99\% | 

This is (again) why eviction is important — without it, partial would approach
full.

Lobsters suggests that significant skew is common. Also ref other
studies on log-normal/zipf/skew.

\subsection{When can partial state be used?}

\begin{itemize}
 \item SELECT COUNT(*) FROM table;
 \item Add ``karma'' query:
   \begin{itemize}
    \item If already have ``karma'' column, trivial in DB. But, equivalent in
      Noria to saying that query was there from the start, so no migration.
    \item If \textbf{not} already have ``karma'' column, DB has two choices:
     \begin{enumerate}
      \item Compute column == expensive, and same as Noria would do
      \item Make query compute value on-demand -- same cost, but repeated!
     \end{enumerate}
   \end{itemize}
 \item TopK
\end{itemize}

\section{What is the cost of using partial state?}
\label{s:eval:cost}

Migrations maybe? Latency timeline to show that early accesses are slow.
Maybe good place to have comparison with Redis? Maybe show vote uniform
numbers? Talk about ``warmup''.

Fig.: throughput vs latency w/wo partial in vote.

Note latency diff for lobsters, and that full fell over due to mem, and
no bigger machine w/o more cores available.

Note that the reason vote falls over when it does is single-core write
processing (since only one query, so one data-flow path).

\section{How does partial state compare to existing solutions?}
\label{s:eval:existing}

This is a difficult question to answer. High-performance solutions are
often developed specifically for a given application, and not available
as general-purpose tools (ref facebook memcache, need cites here).
And applying the general-purpose tools that \textbf{are} available (memcache,
redis) effectively, requires significant effort on the part of the
application authors (or the evaluators). To manually add caching support
to Lobsters' XX queries, including mitigation, thundering herd
mitigation, and incremental updates would be a massive undertaking.

In some sense, this alone is an argument for Noria's approach. Since the
database uses information it already possesses (in the form of
application queries) to automatically optimize accesses through
materialization, it is relatively easy to take advantage of the benefits
that Noria provides.

Nonetheless, to shed some light on the absolute performance that Noria
provides against a caching system, I include below a performance
comparison between Noria and Redis. To approximate how a carefully
planned and optimized application caching deployment might perform, it
runs a workload that is idealized for a caching system:

\begin{itemize}
 \item Every Redis access hits in cache, to emulate perfect thundering herd
   mitigation and invalidation-avoidance schemes.
 \item Nearly all accesses (99.9\%) are reads, since writes would be
   bottlenecked by the backing store.
 \item All accesses are for a single integer value, to emulate a system that has
   perfect cache coverage. Request access keys are chosen according to a Zipfian
    distribution with $\alpha = 1.08$ (moderate skew).
 \item Accesses are batched to reduce serialization cost and increase
   throughput. Specifically, reads are \texttt{MGET}s, and writes are pipelined
    \texttt{INCRBY}s.
\end{itemize}

This is not a realistic use of Redis, but it allows us to ``assume the best''
about the underlying caching strategy and system. The benchmark runs for four
minutes, and then samples latencies for another two minutes.

Fig.: throughput vs 95\%-ile latency [noria,redis]

Redis is single threaded, which necessarily limits its performance. If we assume
perfect sharding, Redis should be able to support 16 times the load on a 16-core
machine. We see that 16x Redis ~= Noria (??), which suggests that Noria is
competitive with manual caching schemes.
