This chapter provides introductory background information on many topics that
are relevant to the work in this thesis, as well as an overview of existing
systems and their relation to Noria and partial state.

\section{Materialized Views}

Noria's primary function is to provide materialized views. In database parlance,
a \textit{view} is a name for the result set of a particular query. When an
application reads from a view, it is reading from the result set that results
from executing that query. Most databases also allow views to be used in place
of other database collections, like tables.

Some databases can \textit{materialize} a view by storing the result set
somewhere for later recollection. When a view is materialized, queries over that
view do not need to re-execute the view's backing query, but instead access the
rows of the view as if they were stored in a durable database relation.
Materialized views thus effectively provide query memoization; they are faster
to access than non-materialized views, at the cost of having to store the view's
rows.

Once a database materializes a view, it must \textit{maintain} that
materialization over time as the underlying data changes. Otherwise, reads from
the view would no longer match the results of the view's backing query. View
maintenance can be \emph{reactive} by updating the view as the data changes,
\emph{demand-driven} by updating the view only when queried, or \emph{triggered}
by updating the view only when an outside trigger is invoked.

Noria implements reactive view maintenance\,---\,it assumes that writes are less
frequent than reads, and therefore that it is better to make writes slower by
updating the cache proactively than to make reads slower by having each read
check that the materialization is up to date.

\paragraph{Materialization.}
Throughout this thesis, the word materialization is often used as a noun. In the
context of Noria, a materialization refers to any derived computation result
that Noria explicitly stores, not just materialized views. Or, more precisely,
Noria may choose to materialize intermediate results, such as the current value
of an aggregation, which do not represent any of the application's queries.
These intermediate materializations are still views\,---\,they have a schema and
consist of rows\,---\,but do not reflect any named views that the application
has created.

\subsection*{Related Work}

Database materialized views~\cite{gupta-view-selection,lee} were originally
devised to cache expensive analytical query results. Unfortunately, commercial
databases' materialized view support is
limited~\cite{materialized-view-selection-sql-server,mssql-materialized-view-restrictions-blog,
mssql-materialized-view-restrictions} and views must usually be rebuilt from
scratch when the underlying data changes.

The key to usable materialized views is how they are maintained incrementally as
the underlying data changes, which has been the subject of considerable research
in the past few decades. \citeauthor{materialized-survey} gives a good survey of
the current landscape in \cite{materialized-survey}.

Modern incremental view maintenance (IVM) techniques are usually based on
\textit{delta queries}, which are algebraically derived queries that give
efficient relational expressions for computing the change to a (materialized)
view given a set of changes to the underlying data. The current state-of-the-art
in IVM is \textit{Higher-Order IVM}, in which the system derives multiple,
recursive such delta queries for each view, and strategically materializes and
maintains the intermediate delta query results as well~\cite{dbtoaster, hotdog}.
Recent work also proposes techniques for mitigating the memory overhead of such
intermediate materializations by instead materializing smaller auxiliary state
from which the necessary values can then be efficiently produced when
needed~\cite{memory-efficient}. Sadly, few of these solutions have been adopted
in commercially available databases.

Noria's dataflow for each view effectively represents delta queries for that
view over the stream of updates to base tables. Noria's current algorithms for
what dataflow to use to compute the changes to each view are fairly naive, and
could likely benefit from the techniques in the aforementioned work. However,
Noria does apply some of the lessons from higher-order delta queries, and
also materializes intermediate results to speed up the delta processing.
Meanwhile, Noria's dataflow-backed processing, while comparatively naive,
provides a significant benefit by virtue of using the dataflow model. In
particular, it allows Noria to easily distribute the view maintenance across
cores and machines to improve performance. Furthermore, Noria is designed to
take advantage of a relaxed consistency model, which allows much higher read
performance than strongly consistent systems can provide.

Through the work of this thesis, Noria also supports \emph{partial} view
materialization, which allows it to materialize and maintain only a subset of
each of the application's views. This is not possible in most existing IVM
systems. Pequod~\cite{pequod} and DBProxy~\cite{dbproxy} support partial
materialization in response to client demand, although Pequod is limited to
static queries specified in a datalog-like language, and DBProxy does not
support incremental view maintenance. And neither system shares state nor
processing across views.

\section{Caching}

As applications grow, their performance needs often exceed that which a
traditional relational database can provide. Such applications cannot afford to
wait for the database to compute joins and aggregations, and need lower-latency
data access than a relational database like MySQL or Postgres typically
provides. In these cases, application authors tend to add \textit{caching} to
their application backend logic.

Caching is a broad topic in and of itself, especially because caching tends to
occur at multiple levels within the application. Developers may cache results of
individual database queries, collections of data that the application frequently
uses together, computed and otherwise derived values that are expensive to
re-compute, segments of rendered application output (like HTML snippets), all
the way to full web pages. Each of these caches may also exist in multiple
places to improve data locality, add redundancy, or simply because two caches
partially overlap.

Noria implements \textit{query result caching} (using materialized views), which
ensures that the application's database queries are fast, even if they are
complex or include significant computation. While Noria could likely be extended
to maintain the compound caches higher up in the application stack, that is left
for future work.

Much like with view materialization, the introduction of caches also requires
that the application maintains those caches such that new data eventually
becomes visible. The exact mechanism that is used to implement the cache
maintenance varies by cache type, developer preference, and application size.

Once a cache is in place, the application authors must also implement cache
\textit{eviction} to ensure that the cache does not grow without bound. Many
eviction strategies exist, but they all revolve around the notion that certain
cache entries are more worthwhile to keep than others. These entries are usually
referred to as ``hot'' entries. Essentially, if storage space is limited, it is
likely better to keep hot a cache entry that is accessed once a second than a
``cold'' entry that was last accessed two weeks ago. \textit{Partial state}, the
topic of this thesis, is what allows Noria to implement eviction for
materialized views.

\subsection*{Related Work}

Application-level caching is often implemented in an ad-hoc fashion, and tends
to be the source of many application errors~\cite{ad-hoc-caching}. Researchers
and industry teams alike have therefore attempted to build systems to automate
cache maintenance.

Large-scale applications often end up building their own custom caching
infrastructure~\cite{facebook-memcache, flannel}, which solves their needs in
isolation, but does not provide a ready-to-use solution for other application
developers that face similar issues. These custom-built solutions also tend to
implement only the minimum functionality the authors need at the time, and
forego more complicated, but nonetheless useful features such as incremental
cache updates.

The research community has also produced several systems that aim to provide
more general-purpose transparent caching. TAO~\cite{tao} and
TxCache~\cite{txcache} implement automated query result caching, but do not
support incremental in-place cache updates. CacheGenie~\cite{cachegenie}
implements a trigger-based middleware cache for object-relational mapping
frameworks, and supports in-place cache updates, but is limited to only specific
operations supported by the framework.

In the world of database literature, database caching frontends are sometimes
referred to as \textit{Cache-Augmented SQL} systems. And there, like with all
caching systems, the primary concern is one of consistency\,---\,\emph{some}
mechanism must be in place to ensure that the cache remains up to date as the
underlying data changes. Research in this space tends to focus on cache
management as being external to the database, and instead augments the key-value
store used to store the cache entries so that this external system can correctly
manage the race conditions that arise when the database and cache are distinct
systems~\cite{facebook-memcache, casql-consistency, casql-consistency-thesis}.
Noria instead integrates the cache management into the database, which allows
the cache entries to be incrementally updated, automatically, in-place.

A related approach is \textit{mid-tier database caching}, in which subsets of
the database are replicated onto the hosts that run the application's code to
allow certain queries to be run locally without interacting with the remote
database backend~\cite{mtcache}. This approach is appealing in that some
database queries can avoid traversing the network, but it does not provide the
same speedups that query result caching provides.

\section{Dataflow}

Noria maintains its materialized views using \textit{dataflow}. Dataflow means a
thousand things to a thousand people, especially if they are from different
areas of computer science, but this thesis will focus on dataflow as understood
in software computing specifically. Even there, many definitions exist, but they
all agree that in dataflow, compute is stationary while data moves.

A dataflow system expresses complex computations as a directed \emph{graph} that
consists of interconnected nodes that implement primitive operations, such as
joins, filters, and aggregations. These nodes then \emph{stream} data among each
other to produce the desired overall results. Dataflow systems are thus also
often referred to as stream processing systems. The roots of the graph produce
the data that the dataflow computes over, whereas the leaves represent the
dataflow program's outputs.

Since the dataflow model is inherently streaming, it is particularly well-suited
for distributed deployments. Nodes are independent, and communicate only through
their streams, and so the system can easily place them on different cores, or
hosts, and use existing messaging fabrics to connect them. If needed, nodes can
also be sharded to allow data-parallel computing.

The streaming design also makes dataflow a good fit for reactive applications.
When the data changes, the system can introduce the changes at the roots, and
then observe how the leaves change in response. Those changes can in turn be
forwarded to the application to provide a change stream over the computation's
results over time.

\subsection*{Related Work}

A wide range of dataflow and stream-processing systems exist that excel at
data-parallel computing~\cite{dryad, naiad, storm, heron, flink, millwheel,
spark-streaming, stanford-stream, s-store, cloud-dataflow}. However, these
systems cannot easily serve web applications directly. They only achieve
low-latency incremental updates at the expense of windowed state (and incomplete
results) or by keeping full state in memory. Partial state allows Noria to lift
this restriction. Furthermore, these systems generally provide no mechanism for
accessing computed state except through the dataflow or by integrating with
additional external systems, which adds latency.

Many existing system are also limited to a fixed set of queries defined when the
system is started, and cannot easily adopt query changes as the application
evolves. Some dataflow systems do support Noria-like dynamic changes to the
running dataflow~\cite{ciel, ray}, but without support for demand-driven partial
state these systems must either fully compute results when the dataflow is
extended, or dataflow changes only take into account subsequent updates.

Some developers use, or consider using, a streaming fabric like Apache
Kafka~\cite{kafka} to build their own view maintenance pipeline~\cite{nyt-kafka,
samza-blogpost}. However, at the time of writing, no general-purpose system
exists based on such a pipeline that achieves the performance and flexibility of
Noria.

Differential dataflow~\cite{differential-dataflow}, and its instantiation in the
commercial product Materialize~\cite{materialize}, bears a striking resemblance
to Noria at first glance. In particular, it uses dataflow to produce
automatically-maintained materialized views over SQL queries. However,
Materialize does not implement partial state, and must therefore maintain
similar queries independently (which misses out on opportunities for shared
compute and state) or fully materialize query results (which uses more memory).
The authors behind Materialize have proposed partial solutions to some of these
challenges, which are discussed in \S\vref{s:disc:emulating}.
