This dissertation proposes a practical system that lowers latency and increases
sustainable throughput for read-heavy web applications by automatically
maintaining a cache of the application's query results. Where traditional
databases re-execute queries each time they are issued, the presented system
stores and maintains a cache of past query results, and uses that to serve
queries more efficiently. As opposed to existing state-of-the-art systems, the
dissertation work supports building the cache on demand, and is able to evict
cache entries in response to a shifting workload.

Experimental results suggest that the presented work increases supported
application load by up to $20\times$ over MySQL, and reduces memory use by up to
$\sfrac{2}{3}$ compared to existing approaches.

\section{Motivation}

Most modern web applications share similar traits. They are
\textbf{interactive}: each page load has a user waiting on the other end. They
are \textbf{read-heavy}: most user interactions consume content rather than
produce new content. And they experience \textbf{significant skew}: a small
number of people, posts, creators, teams, and discussions make up the bulk of
interactions.

Such applications are usually poorly served by the traditional relational
databases that most of them use to store and query their underlying data.
These application tend to issue the same read-only queries again and again, with
the underlying data changing only infrequently. Existing databases do
not optimize for this kind of workload: they run each query in isolation, and
thus re-do work that has already been done many times over.

As a result, application authors often resort to ad-hoc, error-prone
techniques~\cite{ad-hoc-caching} to exploit their applications' workload
patterns and satisfy impatient users. They de-normalize their database schemas
by placing and updating computed values in the database tables, or introduce
key-value stores that \textit{cache} the result of expensive queries. All these
techniques introduce significant application complexity: the application authors
must include logic to ensure that the auxiliary derived state remains up to date
as the underlying data changes, that clients do not all flood the database when
results are not available in the cache, and that concurrent access to the
database and the cache never leaves the system in an inconsistent state.

\section{Existing Solutions}

Existing systems from industry~\cite{facebook-memcache, tao, flannel} and
academia~\cite{txcache, cachegenie, casql-consistency-thesis, pequod} have
attempted to chip away at this problem, but are often lacking in important ways.
Some require significant developer effort, and are infeasible to implement for
any but the largest companies. Some support only a restricted set of application
queries, or only provide infrastructure for developers to implement caching
themselves. Many maintain cached results only by evicting old results, and
cannot updating existing results in-place, which is wasteful.

% Noria replaces caching \emph{logic}, not caching just caching \emph{systems}.

Eons ago, the database community produced \textit{materialized views} as a
potential answer to the slow query problem. Materialized views store the results
of \textit{views} (i.e., named queries) with the goal of making those queries
faster to execute~\cite{materialized-views}. These materialized views can then
be maintained incrementally rather than re-executing queries when the underlying
data changes~\cite{materialized-survey}. However, few commercially available
databases support materialized views, and the ones that do come with significant
restrictions~\cite{mssql-materialized-view-restrictions}.

State-of-the-art research systems support flexible materialized
views~\cite{dbtoaster,materialize}, but do not support eviction or low-latency
reads\footnote{In these systems, reads cannot access the materialized view
directly, and must synchronize with the write-processing pipeline to extract
query results.}, and thus function poorly as a replacement for a cache. Many
recent state-of-the-art materialized view systems are also restricted to a
pre-declared set of queries, and cannot incorporate changes to the application
query set without restarting.

\section{Approach: Partial State}

This thesis proposes \textit{partial state} in Noria, a state-of-the-art
materialized view system that is already optimized for read-heavy, dynamic web
applications~\cite{noria}. Partial state enables Noria to materialize results
for queries on-demand and evict results when they are no longer useful.

Noria uses \textit{dataflow} to maintain its materialized views, a system
architecture that allows fast and distributed computation over a stream of data
changes. It represents computational dependencies as a directed acyclic graph
where edges represent data dependencies, and vertices represent computations
(like aggregations or joins) over the data that arrives over the incoming edges.
The work in this thesis adds support for partial state to Noria's dataflow so
that most of Noria's existing systems can be re-used.

Partial state allows state in Noria's materialized views to be marked as
\textit{missing}, and introduces \textit{upqueries} as a mechanism to compute
such missing state on-demand. Upqueries re-use the existing dataflow operators
that maintain the materialized views, and can theoretically be retrofitted onto
any existing dataflow system.

\section{Contributions}

The main contributions of this thesis are:

\begin{itemize}
 \item A model for, and implementation of, partial state in a dataflow-based
   materialized view system.
 \item An algorithm for implementing upqueries to populate missing state on
   demand.
 \item An analysis of the issues that arise when introducing partial state to a
   distributed, high-performance stateful dataflow processing system.
 \item Techniques for overcoming those issues while preserving system
	 correctness, performance, and scalability.
 \item Micro and macro evaluations of the performance and memory impact of
	 introducing partial state to dataflow.
\end{itemize}

\paragraph{Dissertation Outline.}

The rest of the dissertation is organized as follows: Section~\ref{s:noria}
describes the Noria dataflow system. Section~\ref{s:partial} introduces the
partially stateful dataflow model. Section~\ref{s:correct} describes additional
mechanisms that are needed to ensure that partially stateful dataflow produces
correct query results. Section~\ref{s:eval} evaluates Noria's implementation of
partial state on a realistic application query workload. Section~\ref{s:related}
explores related work. Section~\ref{s:disc} discusses shortcomings of, and
alternatives to, partial state. Finally, Section~\ref{s:future} outlines future
work on partial state.

For readers that are unfamiliar with database queries, materialized views,
dataflow, and application caching, but would still like to understand roughly
what this thesis is about, Appendix~\ref{s:simple} starting on
page~\pageref{s:simple} is for you.
