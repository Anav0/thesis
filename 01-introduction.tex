Many of the most popular applications today are content-heavy web applications.
Social networking platforms like Facebook and LinkedIn, content platforms like
Twitter and Wikipedia, communication platforms like Slack and Discord, and
discussion platforms like Reddit and Hacker News all process, display, and
disseminate user-generated content. They share no code, yet they all share an
underlying core feature: they have large amounts of data, and must query that
data every time a user interacts with the site.

These platforms also exhibit many similar traits:
%
\begin{enumerate*}
  \item they are \textbf{interactive}; each page load has a user waiting on the
    other end,
  \item they are \textbf{read-heavy}; most user interactions consume content
    rather than produce new content, and
  \item they experience \textbf{significant skew}; a small number of people,
    posts, creators, teams, and discussions make up the bulk of interactions.
\end{enumerate*}
%
Taken together, these properties suggest that these platforms would benefit
from \emph{caching}\,---\,from a system that ``remembers'' results from past
user requests, and recalls those results efficiently if another user later
requests the same data. Since a user is waiting at the other end of every
request, caching is \emph{necessary} to avoid making the user wait for too long.
Since the platforms are read-heavy, the advantages for reads from caching are
likely to outweight the cost of maintaining the cache. And since access is
skewed, caching even a small fraction of the overall dataset is likely to bring
significant benefits.

Most applications implement caching in an ad-hoc way\,---\,developers introduce
complex and error-prone logic~\cite{ad-hoc-caching} to ensure that changes to
the underlying data are also reflected in results served from the cache. Some
systems, both from industry~\cite{facebook-memcache, tao, flannel} and
academia~\cite{txcache, cachegenie, casql-consistency-thesis, pequod} have
attempted to chip away at this problem, but are often lacking in important ways.
Some require significant developer effort, while others support only a
restricted set of application queries.

A promising avenue for automating at least part of the application caching
problem is \emph{query result caching} through a technique known as
\emph{materialized views}. Materialized views allow an application backend, like
a database, to pre-compute, store, and maintain results for an application's
queries such that subsequent executions of those same queries can be served much
more quickly. Unfortunately, materialized views are typically an all-or-nothing
affair; each query is computed independently, and its full result set is cached.
While this is acceptable for a small number of analytics-type queries, it is a
problem when the application issues a large number of similar, but not identical
queries that must all be answered quickly. Either the common superset of those
queries must be computed in full, which uses significant memory, or each query's
materialized view must be maintained individually, which causes unnecessary
duplicate processing.

This thesis proposes a technique to introduce \textit{partial state} into Noria,
a materialized view system implemented using dataflow~\cite{noria}. Partial
state allows Noria to represent similar queries in a single, shared materialized
view, without simultaneously requiring that the results for \emph{all} such
queries be cached as a result. This let Noria avoid expending memory to cache
query results the application is not interested in, while also allowing similar
queries to share cache maintenance processing.

The work in this thesis proposes to allow individual query results to be marked
as \textit{missing}, and introduces \textit{upqueries} as a mechanism to compute
such missing state on-demand. Upqueries re-use the existing dataflow operators
that maintain the materialized views as the underlying data changes in Noria,
and can thus theoretically be retrofitted onto an existing dataflow system.
Partial state also enables Noria to evict cached results over time as the
application workload changes, which is critical to keep memory use low.

Experiments with partial state in Noria suggest that materialized views
implemented using partial state can increase the supported application load by
up to $20\times$ over MySQL, and can reduce memory use by $\sfrac{2}{3}$
compared to materialized views implemented without partial state.

% Existing materialized view systems also tend to focus on view-update
% performance.

% Commercial materialized views?

% Windowing?

% Replace caching \emph{logic}, not caching \emph{systems}.

\paragraph{Contributions.}

The main contributions of this thesis are:

\begin{itemize}
 \item A model for, and implementation of, partial state in a dataflow-based
   materialized view system.
 \item An algorithm for implementing upqueries to populate missing state on
   demand.
 \item An analysis of the issues that arise when introducing partial state to a
   distributed, high-performance stateful dataflow processing system.
 \item Techniques for overcoming those issues while preserving system
	 correctness, performance, and scalability.
 \item Micro and macro evaluations of the performance and memory impact of
	 introducing partial state to dataflow.
\end{itemize}

\paragraph{Dissertation Outline.}

The rest of the dissertation is organized as follows: Section~\ref{s:bg}
introduces concepts and terminology used throughout the thesis, and explores
related work. Section~\ref{s:noria} describes the Noria dataflow system.
Section~\ref{s:partial} introduces the partially stateful dataflow model.
Section~\ref{s:correct} describes additional mechanisms that are needed to
ensure that partially stateful dataflow produces correct query results.
Section~\ref{s:eval} evaluates Noria's implementation of partial state on a
realistic application query workload. Section~\ref{s:disc} discusses
shortcomings of, and alternatives to, partial state. Finally,
Section~\ref{s:future} outlines future work on partial state.

For readers that are unfamiliar with database queries, materialized views,
dataflow, and application caching, but would still like to understand roughly
what this thesis is about, Appendix~\ref{s:simple} starting on
page~\pageref{s:simple} is for you.
