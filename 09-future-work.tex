\section{Efficient Migrations}

Section~\ref{s:eval:mig} demonstrated that partial state makes some migrations
efficient. This requires that the view \emph{can} be partial, as per the
discussion above. But even for views that can be partial, work may be required
in order to make upqueries for that view efficient. This work generally means
adding an index to some existing state, which requires scanning the data stored
in that view. Constructing an index tends to be significantly faster than
computing the full cached results of the new view, but it is a non-trivial cost
nonetheless.

For example, consider the query in Listing~\vref{l:karma} when added to the vote
benchmark query in Listing~\vref{l:votes}. To simplify the argument, assume that
the \texttt{VoteCount} view is \emph{not} partially stateful (i.e., it holds all
the rows). For upqueries of the new view to be efficient, it must be possible to
query all the stories (along with their vote counts) for a given author in the
\texttt{VoteCount} view that existed previously. This means we must add an index
on the \texttt{author} column of that view's state, which is costly.

\begin{listing}[h]
  \begin{minted}{sql}
    SELECT VoteCount.author,
           SUM(VoteCount.nvotes) AS karma
    FROM VoteCount -- the view from the vote benchmark
    GROUP BY VoteCount.author
    WHERE VoteCount.author = ?
  \end{minted}
  \caption{Query that computes the sum total score of a user's stories
  (their ``karma'').}
  \label{l:karma}
\end{listing}

A comparison with what would happen when using a traditional relational database
is useful here. When the application developer decides that they want to run
this new query, they have two choices: either compute it on-demand, or
denormalize the schema by adding a new computed ``karma'' column to the
(hypothesized) \texttt{users} table. Neither option is great. The former is slow
to execute, and the latter requires computing the karma for every story. The
index Noria must construct for efficient upqueries is cheaper to construct than
such a computed \texttt{karma} column, which makes Noria's single scan seem
reasonable.

Note that if \texttt{VoteCount} \emph{is} partial, the karma view is free to
construct for Noria since indices for partially stateful materializations always
start out empty. Noria constructs an empty index by author, and then fills it on
demand as the application executes the karma query for particular authors.

Whether Noria \emph{always} does no more work than what a developer would
make a traditional relational database do if they wanted to make a view
efficient to query remains an open question.

\section{Ordered State}
\label{s:disc:ordered}

Certain ordered operations, like max aggregations (\texttt{SELECT MAX}) and
top-k-style queries (\texttt{ORDER BY LIMIT}), occasionally require re-fetching
underlying state as the data changes. If the maximum value in a max aggregation
or a row in a top-k view is removed, the new view content can only be determined
by re-evaluating the query.

The necessary upquery can be performed efficiently if the underlying state is
maintained in the appropriate order, but Noria does not currently support the
necessary ordered indexes. Instead, Noria provides approximate versions of such
operators. In particular, Noria's top-k operator maintains the top $2k$ items,
so that if an item is removed, the top $k$ items are still known. To get back to
$2k$ (to allow future removals), the operator fills the top view with the
highest rows it has seen so far.

This scheme avoids the need for upqueries, and works well as long as removals
from the top list are uncommon and the top list rotates over time. Otherwise,
the approach is brittle; if many top rows are removed, or if the top is changing
very infrequently, the top list may eventually hold none of the actual top
items. Support for ordered indexes, and limited upqueries against those indexes,
would address this limitation.

\section{Ranged Upqueries}
\label{s:disc:ranged}

Throughout this thesis, upqueries have been described in terms of point lookups
of the form \texttt{WHERE x = ? AND y = ?}. However, the design of partial state
is also amenable to supporting ranged queries (\texttt{WHERE x = ? AND y < ?}).
Much of the necessary work lies in changing the appropriate index structures and
including range information in upqueries, which is all straightforward. The
trickiest part of the change is to ensure that future updates are not dropped if
they fall within a requested range. For example, consider the following course
of events:

\begin{enumerate}
  \item An insert arrives with \texttt{x = 42}.
  \item An upquery arrives with \texttt{x < 50}.
  \item An insert arrives with \texttt{x = 49}.
\end{enumerate}

The second insert must be forwarded downstream so it will update the
materialized state for \texttt{x < 50}. For Noria to realize this, it must
``remember'' the \texttt{x < 50} upquery. More generally, it must remember what
\emph{ranges} of values are present downstream, not just what individual keys.
The solution here is to use an interval tree to track which parts of the key
space is present. An interval tree efficiently stores, merges, and splits ranges
as new ones are introduce (by new upqueries) and retired (by evictions).

\section{Sharding Upquery Explosions}

An unfortunate phenomenon manifests for queries when partial state and sharding
combine in a detrimental way. If $Q$ is $R$'s parent, $R$ is sharded differently
from $Q$, $Q$ is partial, and $Q$'s materialized ancestor $P$ is sharded
differently from $Q$, then a miss in $R$ may cause $k^2$ upqueries to $P$, where
$k$ is the sharding factor. The miss in $R$ generates an upquery to every shard
of $Q$, and every shard of $Q$ sends an upquery to every shard of $P$.

The three modifications from \S\ref{s:challenge:sharding} are sufficient to
ensure that Noria handles this situation \emph{correctly}, but more research is
needed to reduce the number of upqueries needed. A promising idea is to optimize
for the case where \emph{all} shards of $Q$ miss. If every shard of $Q$ knows
that every other shard will upquery $P$, they may be able to coordinate the
upqueries such that any given key is only upqueried once. The sharder node can
then ensure that the upquery results are sent to all the shards. This is left
for future work.

\section{Fault Tolerance}

If an operator's state is lost, Noria's current recovery strategy is to remove
and re-introduce the operator, and all of its descendants, as if they were new
queries. This can happen because the Noria worker hosting that operator fails,
or simply because the system is restarted. This scheme works, but means that any
past materialization work is lost and must be re-done.

A mechanism for taking snapshots of materialized state that can be recovered
later would help mitigate this. However, such a design also requires care to
ensure that any state populated \emph{since} the snapshot is correctly
incorporated. In particular, if downstream state now includes entries that
reflect data missing from the snapshot, the system must evict that downstream
state. Otherwise, updates for that data will be discarded at the recovered
operator when it discovers that the related state is missing in its state.

\section{Upstream Database Integration}

Existing applications that wish to adopt Noria may not want to do so wholesale.
They may wish to continue using their existing data backend because they rely on
its transactional properties, because they trust their current backup system, or
simply to make the transition incrementally.

The most straightforward way to add Noria to an existing application backend is
to feed all changes to the primary database tables into Noria. Noria will then
maintain its copies of the base tables, with indexes it manages itself. However,
this has the downside of duplication all of the application's data between the
primary backend and Noria.

A more attractive alternative is to integrate the existing backend into Noria's
base tables. Noria would still have to be notified as changes are made to the
data so that it can propagate those changes to the maintained views, but that
data would not also have to be stored in Noria's base tables.

Unfortunately, this design introduces a race condition: there is now a window of
time where a change that has been made to the base data is visible to upqueries
to the base tables, but the corresponding update has not yet entered the
dataflow. This is a problem, because if an upquery response reflects that new
data, and then an update arrives and adds that same data, the data will be
reflected twice and thus violate Invariant~\ref{i:no-spurious}. In many ways,
this is a similar problem to the one that joins face if their input state
resides across an edge that may hold in-flight updates
(\S\ref{s:join-state-dupe}).

A possible solution is to take a page out of the multi-version concurrency
control playbook, and ensure that lookups into base table state do not see the
effects of any updates that have not yet passed through its Noria operator
equivalent. Ideally, this would be based on the existing transactional
capabilities of the upstream database, but it may also be possible to emulate
using an audit table that records table changes.

\section{Maintaining Downstream Systems}

Noria propagates deltas internally, and these deltas may useful to downstream
systems. For example, Noria could notify a reactive web application when the
result set for the currently displayed view is modified, and include in that
notification what changed. In response, the application could reflect that
change, all without sending another query to the database.

Extending Noria in this way raises an interesting question around partial state.
What happens if an application ``subscribes'' to a query, and then that query's
result set is evicted? Since it is evicted, Noria will not maintain it any
longer, and the application's view will grow stale. Similarly, what happens if
the application attempts to subscribe to a query whose results are not yet
known? Or, what if the application goes offline briefly, and now wishes to
gather only the changes to the result set since it was last online?

It may be that the solution here is simple\,---\,provide a query-and-subscribe
RPC that populates missing state if needed, and ensures that results for
outstanding subscriptions are never evicted. The view could also retain a log of
recent changes to the view for if a stale client wants to catch up.

\section{Eviction Strategy}

Partial state enables Noria to evict state that is infrequently accessed. It
does not dictate any particular eviction strategy as long as the partial state
invariants are maintained. In particular, if state is evicted at some operator,
any downstream state derived from the evicted state must also be evicted.

This thesis does not attempt to innovate in the space of eviction schemes, and
implements simple randomized eviction: when memory use exceeds a given
threshold, keys are evicted randomly from the three largest indices in each of
the three largest domains. The number of keys is chosen proportionally to the
size of each state. This scheme works decently, and requires little coordination
or complexity, but suffers when the system runs close to capacity. Frequently
accessed keys may still be evicted due to pure chance, and when that happens the
system falls behind.

To push Noria's performance, a smarter eviction strategy should be implemented.
The primary obstacle to overcome is that evictions must happen in the dataflow
write path, but the information needed to inform eviction decisions usually come
from the read path. Care must be taken to avoid excessive synchronization
between these, otherwise Noria's read performance would be bottlenecked by the
performance of the write path.

\section{Cursors}

Websites frequently have paginated listings, or pages that fill in with more
content as the user scrolls. Behind the scenes, these techniques are implemented
using the same abstract mechanism: the cursor. There are many ways to implement
cursors, but the most common is the \texttt{LIMIT} operator.

On page one of a listing page with 10 results per page, the application runs the
listing query with \texttt{LIMIT 10}. On page two, it runs the same query with
\texttt{OFFSET 10} to skip the results from page one, or with a \texttt{WHERE}
clause that excludes results that have already been shown. For example, if the
listing query orders results by id, the \texttt{WHERE} clause could be
\texttt{id > ?} where \texttt{?} is the last id on the previous page.

Some databases support persistent cursors. The database tracks what subset of
the results for a query the application has already seen, and the application
can fetch more results directly from the cursor.

Noria currently cannot represent cursors like these since it does not maintain
the order of in-memory state (\S\ref{s:disc:ordered}). \texttt{OFFSET} might not
skip the same results as shown on the previous page, and \texttt{WHERE x > ?} is
not supported. If support for ordered state was added, Noria would support these
types of queries much like existing databases.

To make paginated queries \emph{partial}, additional challenges must be solved.
First, ranged upqueries are required for \texttt{x > ?} conditionals
(\S\ref{s:disc:ranged}). Then, a decision must be made as to how \texttt{LIMIT}
should interact with upqueries. There are two primary design options:
\emph{post-limiting} and \emph{pre-limiting}.

In a post-limited design, the query is executed without pagination-related
clauses internally, and all of its results are materialized. The limit and
offset are then applied ``at the end'': when a query execution request comes in,
only an appropriate subset of the materialized results are returned. This
solution requires no changes to the partial state logic, but also makes it
necessary to materialize all pages of each query result, even if only the first
few pages are ever accessed. Realistically, a solution that takes this approach
would therefore also include a hard upper limit on how many results are
materialized. Twitter takes an approach like this, where there is a fixed end to
each timeline that the user cannot scroll past.

In a pre-limited design, only results for pages that have been accessed are
materialized. This is attractive since it uses less memory, and fewer results
must be maintained. But, it also requires more complex changes to partial state.
In particular, operators must now have a way to determine if a state change
causes records to appear in, or disappear from, materialized pages downstream.
If they do not, updates may be discarded early even though they would change
downstream materialized state. Furthermore, since intermediate operators may
remove (e.g., filters) or add (e.g., joins) rows to the result set, the limit
requested by the application may not map directly to the number of results
yielded by the corresponding upquery. Therefore, page-specific upqueries may
need to run multiple ``iterations'' to fetch additional results if the first
response did not return enough rows.

\section{Column-Based Storage}

Noria's in-memory storage is unoptimized. Specifically, every row in every
materialization is allocated in its own vector. This stresses the memory
allocator, and introduces non-trivial memory overhead. Since Noria knows the
schema of each view in advance, and all rows in the view have the same schema, a
column-based storage format would likely be a much better fit for many views.
Noria could even use heuristics to choose between row- and column-based storage
depending on the semantics of each operator.

\section{Time-Windowed Operators}

Noria has no support for time-windowed queries\,---\,those that include
\texttt{NOW}, \texttt{CURRENT TIME}, or other similar dynamic values in the
query. These queries are difficult as they are not pure functions of the data in
the base tables. Instead, the query results change continuously, even if the
application instigates no changes. How to support such operators in Noria, and
with partial state which also relies on the purity of operators, remains an open
problem.

\section{Partial Key Subsumption}

Noria's implementation of partial state does not currently take advantage of
situations where upquery keys overlap. For example, consider the case of an
operator X where one downstream operator upqueries on column A, and another
upqueries on the pair of columns A and B. X currently keeps two indices: one on
A, and one on A+B. Each index keeps track of missing entries independently. So,
even if we previously executed and filled in an upquery for A = 3, a subsequent
request for A = 3, B = foo could miss and cause another upquery to be issued.
The operator has sufficient information that it should be able to resolve this
index miss locally, but Noria does not currently implement this optimization.
